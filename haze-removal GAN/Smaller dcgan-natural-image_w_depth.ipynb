{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras import losses\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from scipy import signal, misc\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import keras.backend.tensorflow_backend as K\n",
    "def get_session():\n",
    "\tconfig = tf.ConfigProto()\n",
    "\tconfig.gpu_options.allow_growth = True\n",
    "\tconfig.gpu_options.allocator_type = 'BFC'\n",
    "\tconfig.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "\treturn tf.Session(config=config)\n",
    "K.clear_session()\n",
    "K.set_session(get_session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CCGAN():\n",
    "    def __init__(self, img_rows = 256, img_cols = 256, mask_height = 15, mask_width = 15, channels = 3, num_classes = 5):\n",
    "        self.img_rows = img_rows\n",
    "        self.img_cols = img_cols\n",
    "        self.mask_height = mask_height\n",
    "        self.mask_width = mask_width\n",
    "        self.channels = channels\n",
    "        self.num_classes = num_classes\n",
    "        self.generator_mse = []\n",
    "        self.discriminator_loss = []\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        \n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "        \n",
    "        #TODO: Build discriminator and compile \n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss = 'binary_crossentropy', optimizer = optimizer,  metrics = ['accuracy'])\n",
    "#         self.discri_parallel = multi_gpu_model(self.discriminator, gpus=3)\n",
    "#         self.discri_parallel.compile(loss = 'binary_crossentropy', optimizer = optimizer,  metrics = ['accuracy'])\n",
    "        #TODO: Build generator and compile\n",
    "        self.generator = self.build_generator()\n",
    "        self.generator.compile(loss = ['binary_crossentropy'], optimizer = optimizer)\n",
    "#         self.gener_parallel = multi_gpu_model(self.generator, gpus=3)\n",
    "#         self.gener_parallel.compile(loss = ['binary_crossentropy'], optimizer = optimizer)\n",
    "        #TODO: The generator takes masked_img = blurred_img as an input\n",
    "        masked_img = Input(shape = self.img_shape)\n",
    "        gen_img = self.generator(masked_img)\n",
    "#         gen_img = self.gener_parallel(masked_img)\n",
    "        \n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "        valid = self.discriminator(gen_img)\n",
    "#         valid = self.discri_parallel(gen_img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator) takes\n",
    "        # masked_img as input => generates images => determines validity \n",
    "        #compile means square error of masked_img and gen_img together with entropy signal backprogate from dicriminator\n",
    "        self.combined = Model(masked_img , [gen_img, valid])\n",
    "#         self.combined_para = multi_gpu_model(self.combined, gpus=3)\n",
    "#         self.combined_para.compile(loss=['mse', 'binary_crossentropy'],\n",
    "#             loss_weights=[1, 0.01],\n",
    "#             optimizer=optimizer)\n",
    "        self.combined.compile(loss=['mse', 'binary_crossentropy'],\n",
    "            loss_weights=[1, 0.01],\n",
    "            optimizer=optimizer)\n",
    "    def build_generator(self):\n",
    "        \n",
    "        model = Sequential()\n",
    "        '''\n",
    "        For the SAME padding, the output height and width are computed as:\n",
    "\n",
    "        out_height = ceil(float(in_height) / float(strides[1]))\n",
    "\n",
    "        out_width = ceil(float(in_width) / float(strides[2]))\n",
    "        And\n",
    "\n",
    "        For the VALID padding, the output height and width are computed as:\n",
    "\n",
    "        out_height = ceil(float(in_height - filter_height + 1) / float(strides[1]))\n",
    "\n",
    "        out_width = ceil(float(in_width - filter_width + 1) / float(strides[2]))\n",
    "        '''\n",
    "        model.add(Conv2D(64, kernel_size = 3, strides = 2, input_shape = self.img_shape,padding = 'same')) #out 128/2 = 64\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(128, kernel_size = 3, strides = 2, padding = 'same')) #out 64/2 = 32\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(256, kernel_size = 3, strides = 2, padding = 'same')) #out 32/2 = 16\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(256, kernel_size = 3, strides = 2, padding = 'same')) #out 16/2 = 8\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(256, kernel_size = 3, strides = 2, padding = 'same')) #out 8/2 = 4\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        # Decoder\n",
    "        model.add(UpSampling2D()) #4*2 = 8\n",
    "        model.add(Conv2D(256, kernel_size=3, padding=\"same\")) # same => 8 \n",
    "        model.add(Activation('relu')) \n",
    "        model.add(UpSampling2D()) #8*2 = 16\n",
    "        model.add(Conv2D(256, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(UpSampling2D()) #16*2 = 32\n",
    "        model.add(Conv2D(256, kernel_size=3, padding=\"same\")) # same => 8 \n",
    "        model.add(Activation('relu')) \n",
    "        model.add(UpSampling2D()) #32*2 = 64\n",
    "        model.add(Conv2D(256, kernel_size=3, padding=\"same\")) # same => 8 \n",
    "        model.add(Activation('relu')) \n",
    "#         model.add(UpSampling2D()) #64*2 = 128\n",
    "#         model.add(Conv2D(64, kernel_size=3, padding=\"same\")) # same => 8 \n",
    "#         model.add(Activation('relu')) \n",
    "#         model.add(UpSampling2D()) #128*2 = 256\n",
    "#         model.add(Conv2D(32, kernel_size=3, padding=\"same\")) # same => 8 \n",
    "#         model.add(Activation('relu')) \n",
    "        model.add(UpSampling2D()) #256*2 = 512\n",
    "        model.add(Conv2D(self.channels, kernel_size=4, padding=\"same\"))\n",
    "        model.add(Activation('tanh'))\n",
    "\n",
    "#         model.summary()\n",
    "\n",
    "        masked_img = Input(shape=self.img_shape)\n",
    "        img = model(masked_img)\n",
    "\n",
    "        return Model(masked_img, img)\n",
    "        \n",
    "    def build_discriminator(self):\n",
    "        model = Sequential()\n",
    "        \n",
    "#         model.add(Conv2D(32, kernel_size = 3, input_shape= self.img_shape, padding = 'same'))\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(MaxPooling2D()) #512/2 = 256\n",
    "        \n",
    "#         model.add(Conv2D(64, kernel_size = 3, padding = 'same'))\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(MaxPooling2D()) #256/2 = 128\n",
    "        \n",
    "        \n",
    "        model.add(Conv2D(64, kernel_size = 3, input_shape= self.img_shape,padding = 'same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D()) #128/2 = 64\n",
    "        #resnet 1\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D()) # 64/2 = 32\n",
    "        \n",
    "        #resnet 2\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D()) # 32/2 = 16\n",
    "        #resnet 3\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D()) # 16/2 = 8\n",
    "        #resnet 4\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D()) # 8/2 = 4\n",
    "        #resnet 5\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D()) # 4/2 = 2\n",
    "        \n",
    "        model.add(Flatten())\n",
    "\n",
    "#         model.summary()\n",
    "        img = Input(shape=self.img_shape)\n",
    "        features = model(img)\n",
    "        valid = Dense(1, activation=\"sigmoid\")(features)\n",
    "#         label = Dense(self.num_classes+1, activation=\"softmax\")(features)\n",
    "#         return Model(img, [valid, label])\n",
    "        return Model(img, valid)\n",
    "\n",
    "    def create_depth_map(self, imgs):\n",
    "        list_output = []\n",
    "        block = 15\n",
    "        for img in imgs:\n",
    "            clone = np.amin(img, axis = 2)  \n",
    "#             clone = 255- clone\n",
    "            list_output.append(clone)\n",
    "        \n",
    "        return np.array(list_output)\n",
    "    \n",
    "    def mask_randomly(self, imgs, time = 1):\n",
    "        masked_imgs = np.empty_like(imgs)\n",
    "        for idx, image in enumerate(imgs): \n",
    "#             cv_img = cv2.cvtColor(image.astype(np.uint8))\n",
    "#             print('type and shape of the image: {type} and {shape}'.format(type = type(cv_img),shape = cv_img.shape))\n",
    "            blur_image = cv2.GaussianBlur(image, (5,5),time)\n",
    "#             print('type and shape of the image: {type} and {shape}'.format(type = type(blur_image),shape = blur_image.shape))\n",
    "            masked_imgs[idx] = blur_image\n",
    "        return masked_imgs\n",
    "        \n",
    "    def load_all_images(self, dir_path, files_extension = None):\n",
    "        file_names = [s for s in os.listdir(dir_path) if not os.path.isdir(os.path.join(dir_path, s))]\n",
    "        file_names = sorted(file_names)\n",
    "        if not files_extension or files_extension == '':\n",
    "            list_names =  [os.path.join(dir_path, file) for file in file_names]\n",
    "        else:\n",
    "            list_names =  [os.path.join(dir_path, file) for file in file_names if file.lower().endswith(files_extension)]\n",
    "        return np.array(list_names)\n",
    "    \n",
    "    def load_images_equivalance_to_names(self, list_names):\n",
    "        array_images = []\n",
    "        for name in list_names:\n",
    "            full_name =  name\n",
    "            img = cv2.cvtColor(cv2.imread(full_name,3), cv2.COLOR_BGR2RGB)\n",
    "            array_images.append(img)\n",
    "        array_images = np.array(array_images)\n",
    "        return array_images\n",
    "    \n",
    "    def normalize_imgs(self, imgs):\n",
    "        imgs = imgs / 255\n",
    "        imgs = 2*imgs -1\n",
    "        return imgs\n",
    "    \n",
    "    def train(self, epochs, batch_size=128, save_interval=50):\n",
    "#         (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "        X_train =  self.load_all_images('smaller origin', 'jpg')\n",
    "        Hazed_imgs = self.load_all_images('smaller hazed', 'jpg')\n",
    "        \n",
    "        half_batch = int(batch_size / 2)\n",
    "\n",
    "        # Class weights:\n",
    "        # To balance the difference in occurences of digit class labels. \n",
    "        # 50% of labels that the discriminator trains on are 'fake'.\n",
    "        # Weight = 1 / frequency\n",
    "        cw1 = {0: 1, 1: 1}\n",
    "        cw2 = {i: self.num_classes / half_batch for i in range(self.num_classes)}\n",
    "        cw2[self.num_classes] = 1 / half_batch\n",
    "        class_weights = [cw1, cw2]\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            #----------------------------\n",
    "            # Train Discriminator\n",
    "            #----------------------------\n",
    "            \n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            names_imgs = X_train[idx]\n",
    "            names_masked_imgs = Hazed_imgs[idx]\n",
    "            imgs = self.load_images_equivalance_to_names(names_imgs)\n",
    "            masked_imgs = self.load_images_equivalance_to_names(names_masked_imgs)\n",
    "            imgs = self.normalize_imgs(imgs)\n",
    "            masked_imgs = self.normalize_imgs(masked_imgs)\n",
    "            #Generates a half batch of new images\n",
    "            gen_imgs = self.generator.predict(masked_imgs)\n",
    "            \n",
    "            valid = np.ones((half_batch, 1))\n",
    "            fake = np.zeros((half_batch, 1))\n",
    "            \n",
    "#===========================================================================\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, valid, class_weight=class_weights)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, valid, class_weight=class_weights)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            \n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random half batch of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            names_imgs = X_train[idx]\n",
    "        \n",
    "            names_masked_imgs = Hazed_imgs[idx]\n",
    "            imgs = self.load_images_equivalance_to_names(names_imgs)\n",
    "            masked_imgs = self.load_images_equivalance_to_names(names_masked_imgs)\n",
    "            imgs = self.normalize_imgs(imgs)\n",
    "            masked_imgs = self.normalize_imgs(masked_imgs)\n",
    "             # Generator wants the discriminator to label the generated images as valid\n",
    "            valid = np.ones((batch_size, 1))\n",
    "            \n",
    "            # Train the generator\n",
    "#             g_loss = self.combined.train_on_batch(masked_imgs, [imgs, valid])\n",
    "            g_loss = self.combined.train_on_batch(masked_imgs, [imgs, valid])\n",
    "\n",
    "            print (\"%d [D loss: %f, acc: %.2f%%] [G loss: %f, mse: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss[0], g_loss[1]))\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % save_interval == 0:\n",
    "                self.generator_mse.append(g_loss[1])\n",
    "                self.discriminator_loss.append(g_loss[0])\n",
    "                # Select a random half batch of images\n",
    "                idx = np.random.randint(0, X_train.shape[0], 3)\n",
    "                names_imgs = X_train[idx]\n",
    "        \n",
    "                names_masked_imgs = Hazed_imgs[idx]\n",
    "            \n",
    "                imgs = self.load_images_equivalance_to_names(names_imgs)\n",
    "                masked_imgs = self.load_images_equivalance_to_names(names_masked_imgs)\n",
    "                imgs = self.normalize_imgs(imgs)\n",
    "                masked_imgs = self.normalize_imgs(masked_imgs)\n",
    "                gen_imgs = self.generator.predict(masked_imgs)\n",
    "                imgs = 0.5 * imgs + 0.5\n",
    "                masked_imgs = 0.5 * masked_imgs + 0.5\n",
    "                gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "#                 print('shapes of imgs, masked_imgs, gen_imgs: ', imgs.shape, masked_imgs.shape, gen_imgs.shape)\n",
    "                self.save_imgs(imgs, masked_imgs, gen_imgs,epoch)\n",
    "                self.save_model(epoch)\n",
    "        \n",
    "    def save_imgs(self,valid_imgs, masked_imgs, generated_images, epoch = -1):\n",
    "        r = 5\n",
    "        c = generated_images.shape[0]\n",
    "        \n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        #fig.suptitle(\"DCGAN: Generated digits\", fontsize=12)\n",
    "#         valid_imgs_shrinked = valid_imgs.squeeze()\n",
    "#         masked_imgs_shrinked = masked_imgs.squeeze()\n",
    "#         gen_imgs_shrinked = generated_images.squeeze()\n",
    "        name = epoch+25\n",
    "        \n",
    "        if not os.path.isdir('dcgan_exp') :\n",
    "            os.mkdir('dcgan_exp')\n",
    "        if not os.path.isdir('dcgan_exp/images 2') :\n",
    "            os.mkdir('dcgan_exp/images 2')\n",
    "        if not os.path.isdir('dcgan_exp/images 2/gernerated') :\n",
    "            os.mkdir('dcgan_exp/images 2/gernerated')    \n",
    "        if not os.path.isdir('dcgan_exp/images 2/masked') :\n",
    "            os.mkdir('dcgan_exp/images 2/masked')\n",
    "        if not os.path.isdir('dcgan_exp/images 2/valid') :\n",
    "            os.mkdir('dcgan_exp/images 2/valid')   \n",
    "        for i in range(c):\n",
    "            cv2.imwrite('dcgan_exp/images 2/generated/{epoch}_generated_{image_at_idx}.jpg'.format(epoch = str(name).zfill(5), image_at_idx = i),cv2.cvtColor(np.array(generated_images[i]*255, dtype = 'uint8'),cv2.COLOR_RGB2BGR))\n",
    "            cv2.imwrite('dcgan_exp/images 2/masked/{epoch}_masked_{image_at_idx}.jpg'.format(epoch = str(name).zfill(5), image_at_idx = i),cv2.cvtColor(np.array(masked_imgs[i]*255, dtype = 'uint8'),cv2.COLOR_RGB2BGR))\n",
    "            cv2.imwrite('dcgan_exp/images 2/valid/{epoch}_valid_{image_at_idx}.jpg'.format(epoch = str(name).zfill(5), image_at_idx = i),cv2.cvtColor(np.array(valid_imgs[i]*255, dtype = 'uint8'),cv2.COLOR_RGB2BGR))\n",
    "            axs[0,i].imshow(valid_imgs[i, :,:])\n",
    "            axs[0,i].axis('off')\n",
    "            axs[1,i].imshow(masked_imgs[i, :,:])\n",
    "            axs[1,i].axis('off')\n",
    "            axs[2,i].imshow(generated_images[i, :,:])\n",
    "            axs[2,i].axis('off')\n",
    "            axs[3,i].imshow(np.abs(masked_imgs[i, :,:]-valid_imgs[i, :,:]))\n",
    "            axs[3,i].axis('off')\n",
    "            plt.subplots_adjust(hspace = .3)\n",
    "            axs[4,i].imshow(np.abs(generated_images[i, :,:]-valid_imgs[i, :,:]))\n",
    "            axs[4,i].axis('off')\n",
    "        fig.savefig(\"dcgan_exp/images 2/natural_image_%d.png\" % name)\n",
    "        plt.close()\n",
    "        \n",
    "    def save_model(self,epoch):\n",
    "        name = epoch + 25\n",
    "        def save(model, model_name,epoch = -1):\n",
    "            if not os.path.isdir('dcgan_exp') :\n",
    "                os.mkdir('dcgan_exp')\n",
    "            if not os.path.isdir('dcgan_exp/saved_models_2') :\n",
    "                os.mkdir('dcgan_exp/saved_models_2')\n",
    "                \n",
    "            model_path = \"dcgan_exp/saved_models_2/{}_epoch_{}.json\".format(model_name, epoch+25)\n",
    "            weights_path = \"dcgan_exp/saved_models_2/{}_weights_epoch_{}.hdf5\".format(model_name , epoch+25)\n",
    "            options = {\"file_arch\": model_path, \n",
    "                        \"file_weight\": weights_path}\n",
    "            json_string = model.to_json()\n",
    "            open(options['file_arch'], 'w').write(json_string)\n",
    "            model.save_weights(options['file_weight'])\n",
    "\n",
    "        save(self.generator, \"dcgan_generator\", name)\n",
    "        save(self.discriminator, \"dcgan_discriminator\", name)\n",
    "        \n",
    "    def load_model(self, file_name1, file_name2):\n",
    "        self.generator = self.build_generator()\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "        self.generator.compile(loss = ['binary_crossentropy'], optimizer = optimizer)\n",
    "        self.generator.load_weights(file_name1)\n",
    "        self.discriminator.compile(loss = 'binary_crossentropy',\n",
    "                                  optimizer = optimizer,\n",
    "                                  metrics = ['accuracy'])\n",
    "        self.discriminator.load_weights(file_name2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    ccgan = CCGAN()\n",
    "    ccgan.train(epochs=500000, batch_size=30, save_interval=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccgan = CCGAN()\n",
    "if not os.path.isdir('dcgan_exp') :\n",
    "    os.mkdir('dcgan_exp')\n",
    "if not os.path.isdir('dcgan_exp/saved_models') :\n",
    "    os.mkdir('dcgan_exp/saved_models')\n",
    "\n",
    "gener_name = \"dcgan_exp/saved_models/ccgan_generator_weights_epoch_249000.hdf5\"\n",
    "discri_name = \"dcgan_exp/saved_models/ccgan_discriminator_weights_epoch_249000.hdf5\"\n",
    "ccgan.load_model(gener_name,discri_name)\n",
    "test_list = ccgan.load_all_images('test data', 'jpg')\n",
    "print(test_list)\n",
    "test_img = ccgan.load_images_equivalance_to_names(test_list)\n",
    "masked_imgs = ccgan.normalize_imgs(test_img)\n",
    "gen_imgs = ccgan.generator.predict(masked_imgs)\n",
    "gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "c = gen_imgs.shape[0]\n",
    "for i in range(c):\n",
    "    cv2.imwrite('{epoch}_generated_now_{image_at_idx}.jpg'.format(epoch = str(i).zfill(5), \n",
    "                                                                                         image_at_idx = i),\n",
    "                cv2.cvtColor(np.array(gen_imgs[i]*255, dtype = 'uint8'),cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccgan = CCGAN()\n",
    "if not os.path.isdir('dcgan_exp') :\n",
    "    os.mkdir('dcgan_exp')\n",
    "if not os.path.isdir('dcgan_exp/saved_models') :\n",
    "    os.mkdir('dcgan_exp/saved_models')\n",
    "\n",
    "gener_name = \"dcgan_exp/saved_models/ccgan_generator_weights_epoch_249000.hdf5\"\n",
    "discri_name = \"dcgan_exp/saved_models/ccgan_discriminator_weights_epoch_249000.hdf5\"\n",
    "ccgan.load_model(gener_name,discri_name)\n",
    "ccgan.train(epochs=250000, batch_size=30, save_interval=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
