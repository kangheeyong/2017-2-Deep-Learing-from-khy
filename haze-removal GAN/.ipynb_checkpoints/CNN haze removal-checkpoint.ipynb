{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.datasets import cifar100\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras import losses\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from scipy import signal, misc\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import keras.backend.tensorflow_backend as K\n",
    "def get_session():\n",
    "\tconfig = tf.ConfigProto()\n",
    "\tconfig.gpu_options.allow_growth = True\n",
    "\tconfig.gpu_options.allocator_type = 'BFC'\n",
    "\tconfig.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "\treturn tf.Session(config=config)\n",
    "K.clear_session()\n",
    "K.set_session(get_session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN():\n",
    "    def __init__(self, img_rows = 256, img_cols = 256, mask_height = 15, mask_width = 15, channels = 3, num_classes = 5):\n",
    "        self.img_rows = img_rows\n",
    "        self.img_cols = img_cols\n",
    "        self.mask_height = mask_height\n",
    "        self.mask_width = mask_width\n",
    "        self.channels = channels\n",
    "        self.num_classes = num_classes\n",
    "        self.generator_mse = []\n",
    "        self.discriminator_loss = []\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        \n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "        \n",
    "        #TODO: Build generator and compile\n",
    "        self.generator = self.build_generator()\n",
    "        self.generator.compile(loss = ['mse'], optimizer = optimizer)\n",
    "        \n",
    "        #TODO: The generator takes masked_img = blurred_img as an input\n",
    "        masked_img = Input(shape = self.img_shape)\n",
    "        gen_img = self.generator(masked_img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator) takes\n",
    "        # masked_img as input => generates images => determines validity \n",
    "        #compile means square error of masked_img and gen_img together with entropy signal backprogate from dicriminator\n",
    "        self.combined = Model(masked_img, gen_img)\n",
    "        #self.combined_parallel_model = multi_gpu_model(self.combined, gpus=4)\n",
    "        self.combined.compile(loss='mse', optimizer=optimizer)\n",
    "    \n",
    "    def build_generator(self):\n",
    "        \n",
    "        model = Sequential()\n",
    "        '''\n",
    "        For the SAME padding, the output height and width are computed as:\n",
    "\n",
    "        out_height = ceil(float(in_height) / float(strides[1]))\n",
    "\n",
    "        out_width = ceil(float(in_width) / float(strides[2]))\n",
    "        And\n",
    "\n",
    "        For the VALID padding, the output height and width are computed as:\n",
    "\n",
    "        out_height = ceil(float(in_height - filter_height + 1) / float(strides[1]))\n",
    "\n",
    "        out_width = ceil(float(in_width - filter_width + 1) / float(strides[2]))\n",
    "        '''\n",
    "        #Encoder\n",
    "        model.add(Conv2D(64, kernel_size = 3, strides = 2, input_shape = self.img_shape,padding = 'same')) #out 128/2 = 64\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(128, kernel_size = 3, strides = 2, padding = 'same')) #out 64/2 = 32\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(256, kernel_size = 3, strides = 2, padding = 'same')) #out 32/2 = 16\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(256, kernel_size = 3, strides = 2, padding = 'same')) #out 16/2 = 8\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(256, kernel_size = 3, strides = 2, padding = 'same')) #out 8/2 = 4\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        # Decoder\n",
    "        model.add(UpSampling2D()) #4*2 = 8\n",
    "        model.add(Conv2D(256, kernel_size=3, padding=\"same\")) # same => 8 \n",
    "        model.add(Activation('relu')) \n",
    "        model.add(UpSampling2D()) #8*2 = 16\n",
    "        model.add(Conv2D(256, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(UpSampling2D()) #16*2 = 32\n",
    "        model.add(Conv2D(256, kernel_size=3, padding=\"same\")) # same => 8 \n",
    "        model.add(Activation('relu')) \n",
    "        model.add(UpSampling2D()) #32*2 = 64\n",
    "        model.add(Conv2D(256, kernel_size=3, padding=\"same\")) # same => 8 \n",
    "        model.add(Activation('relu')) \n",
    "        model.add(UpSampling2D()) #256*2 = 512\n",
    "        model.add(Conv2D(self.channels, kernel_size=4, padding=\"same\"))\n",
    "        model.add(Activation('tanh'))\n",
    "\n",
    "#         model.summary()\n",
    "\n",
    "        masked_img = Input(shape=self.img_shape)\n",
    "        img = model(masked_img)\n",
    "\n",
    "        return Model(masked_img, img)\n",
    "        \n",
    "    def mask_randomly(self, imgs, time = 1):\n",
    "        masked_imgs = np.empty_like(imgs)\n",
    "        for idx, image in enumerate(imgs): \n",
    "#             cv_img = cv2.cvtColor(image.astype(np.uint8))\n",
    "#             print('type and shape of the image: {type} and {shape}'.format(type = type(cv_img),shape = cv_img.shape))\n",
    "            blur_image = cv2.GaussianBlur(image, (5,5),time)\n",
    "#             print('type and shape of the image: {type} and {shape}'.format(type = type(blur_image),shape = blur_image.shape))\n",
    "            masked_imgs[idx] = blur_image\n",
    "        return masked_imgs\n",
    "        \n",
    "    def load_all_images(self, dir_path, files_extension = None):\n",
    "        file_names = [s for s in os.listdir(dir_path) if not os.path.isdir(os.path.join(dir_path, s))]\n",
    "        file_names = sorted(file_names)\n",
    "        if not files_extension or files_extension == '':\n",
    "            list_names =  [os.path.join(dir_path, file) for file in file_names]\n",
    "        else:\n",
    "            list_names =  [os.path.join(dir_path, file) for file in file_names if file.lower().endswith(files_extension)]\n",
    "        return np.array(list_names)\n",
    "    \n",
    "    def load_images_equivalance_to_names(self, list_names):\n",
    "        array_images = []\n",
    "        for name in list_names:\n",
    "            full_name =  name\n",
    "            img = cv2.cvtColor(cv2.imread(full_name,3), cv2.COLOR_BGR2RGB)\n",
    "            array_images.append(img)\n",
    "        array_images = np.array(array_images)\n",
    "        return array_images\n",
    "    \n",
    "    def normalize_imgs(self, imgs):\n",
    "        imgs = imgs / 255\n",
    "        imgs = 2*imgs -1\n",
    "        return imgs\n",
    "    def train(self, epochs, batch_size=128, save_interval=50):\n",
    "#         (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "        X_train =  self.load_all_images('smaller origin', 'jpg')\n",
    "        Hazed_imgs = self.load_all_images('smaller hazed', 'jpg')\n",
    "        \n",
    "        half_batch = int(batch_size / 2)\n",
    "\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random half batch of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            names_imgs = X_train[idx]\n",
    "            names_masked_imgs = Hazed_imgs[idx]\n",
    "            \n",
    "            imgs = self.load_images_equivalance_to_names(names_imgs)\n",
    "            masked_imgs = self.load_images_equivalance_to_names(names_masked_imgs)\n",
    "            \n",
    "            imgs = self.normalize_imgs(imgs)\n",
    "            masked_imgs = self.normalize_imgs(masked_imgs)\n",
    "            # Train the generator\n",
    "            gen_imgs = self.generator.predict(masked_imgs)\n",
    "            g_loss = self.combined_parallel_model.train_on_batch(gen_imgs, imgs)\n",
    "        \n",
    "             # Plot the progress\n",
    "#             print (\"%d [D loss: %f, acc: %.2f%%, op_acc: %.2f%%] [G loss: %f, mse: %f]\" % (epoch, d_loss[0], 100*d_loss[3], 100*d_loss[4], g_loss[0], g_loss[1]))\n",
    "            print (\"%d  [G loss: %f]\" % (epoch, g_loss ))\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % save_interval == 0:\n",
    "                self.generator_mse.append(g_loss)\n",
    "                self.discriminator_loss.append(g_loss*1.1)\n",
    "                # Select a random half batch of images\n",
    "                idx = np.random.randint(0, X_train.shape[0], 3)\n",
    "                names_imgs = X_train[idx]\n",
    "        \n",
    "                names_masked_imgs = Hazed_imgs[idx]\n",
    "            \n",
    "                imgs = self.load_images_equivalance_to_names(names_imgs)\n",
    "                masked_imgs = self.load_images_equivalance_to_names(names_masked_imgs)\n",
    "                imgs = self.normalize_imgs(imgs)\n",
    "                masked_imgs = self.normalize_imgs(masked_imgs)\n",
    "                gen_imgs = self.generator.predict(masked_imgs)\n",
    "                imgs = 0.5 * imgs + 0.5\n",
    "                masked_imgs = 0.5 * masked_imgs + 0.5\n",
    "                gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "#                 print('shapes of imgs, masked_imgs, gen_imgs: ', imgs.shape, masked_imgs.shape, gen_imgs.shape)\n",
    "                self.save_imgs(imgs, masked_imgs, gen_imgs,epoch)\n",
    "                self.save_model(epoch)\n",
    "        \n",
    "    def save_imgs(self,valid_imgs, masked_imgs, generated_images, epoch = -1):\n",
    "        r = 5\n",
    "        c = generated_images.shape[0]\n",
    "        \n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        #fig.suptitle(\"DCGAN: Generated digits\", fontsize=12)\n",
    "#         valid_imgs_shrinked = valid_imgs.squeeze()\n",
    "#         masked_imgs_shrinked = masked_imgs.squeeze()\n",
    "#         gen_imgs_shrinked = generated_images.squeeze()\n",
    "        if not os.path.isdir('CNN_exp') :\n",
    "            os.mkdir('CNN_exp')\n",
    "        if not os.path.isdir('CNN_exp/images') :\n",
    "            os.mkdir('CNN_exp/images')\n",
    "        if not os.path.isdir('CNN_exp/images/gernerated') :\n",
    "            os.mkdir('CNN_exp/images/gernerated')    \n",
    "        if not os.path.isdir('CNN_exp/images/masked') :\n",
    "            os.mkdir('CNN_exp/images/masked')\n",
    "        if not os.path.isdir('CNN_exp/images/valid') :\n",
    "            os.mkdir('CNN_exp/images/valid')       \n",
    "    \n",
    "        for i in range(c):\n",
    "            cv2.imwrite('CNN_exp/images/generated/{epoch}_generated_{image_at_idx}.jpg'.format(epoch = str(epoch).zfill(5), image_at_idx = i),cv2.cvtColor(np.array(generated_images[i]*255, dtype = 'uint8'),cv2.COLOR_RGB2BGR))\n",
    "            cv2.imwrite('CNN_exp/images/masked/{epoch}_masked_{image_at_idx}.jpg'.format(epoch = str(epoch).zfill(5), image_at_idx = i),cv2.cvtColor(np.array(masked_imgs[i]*255, dtype = 'uint8'),cv2.COLOR_RGB2BGR))\n",
    "            cv2.imwrite('CNN_exp/images/valid/{epoch}_valid_{image_at_idx}.jpg'.format(epoch = str(epoch).zfill(5), image_at_idx = i),cv2.cvtColor(np.array(valid_imgs[i]*255, dtype = 'uint8'),cv2.COLOR_RGB2BGR))\n",
    "            axs[0,i].imshow(valid_imgs[i, :,:])\n",
    "            axs[0,i].axis('off')\n",
    "            axs[1,i].imshow(masked_imgs[i, :,:])\n",
    "            axs[1,i].axis('off')\n",
    "            axs[2,i].imshow(generated_images[i, :,:])\n",
    "            axs[2,i].axis('off')\n",
    "            axs[3,i].imshow(np.abs(masked_imgs[i, :,:]-valid_imgs[i, :,:]))\n",
    "            axs[3,i].axis('off')\n",
    "            plt.subplots_adjust(hspace = .3)\n",
    "            axs[4,i].imshow(np.abs(generated_images[i, :,:]-valid_imgs[i, :,:]))\n",
    "            axs[4,i].axis('off')\n",
    "    \n",
    "        fig.savefig(\"CNN_exp/images/natural_image_%d.png\" % epoch)\n",
    "        plt.close()\n",
    "        \n",
    "    def save_model(self,epoch):\n",
    "\n",
    "        def save(model, model_name,epoch = -1):\n",
    "            if not os.path.isdir('CNN_exp') :\n",
    "                os.mkdir('CNN_exp')\n",
    "            if not os.path.isdir('CNN_exp/saved_models') :\n",
    "                os.mkdir('CNN_exp/saved_models')\n",
    "                \n",
    "            model_path = \"CNN_exp/saved_models/{}_epoch_{}.json\".format(model_name, epoch)\n",
    "            weights_path = \"CNN_exp/saved_models/{}_weights_epoch_{}.hdf5\".format(model_name , epoch)\n",
    "            options = {\"file_arch\": model_path, \n",
    "                        \"file_weight\": weights_path}\n",
    "            json_string = model.to_json()\n",
    "            open(options['file_arch'], 'w').write(json_string)\n",
    "            model.save_weights(options['file_weight'])\n",
    "\n",
    "        save(self.generator, \"CNN_generator\", epoch)\n",
    "\n",
    "        \n",
    "    def load_model(self, file_name):\n",
    "        self.generator = self.build_generator()\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "        self.generator.compile(loss = ['binary_crossentropy'], optimizer = optimizer)\n",
    "        self.generator.load_weights(file_name)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    ccgan = CNN()\n",
    "    ccgan.train(epochs=100000, batch_size=15, save_interval=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN()\n",
    "if not os.path.isdir('CNN_exp') :\n",
    "    os.mkdir('CNN_exp')\n",
    "if not os.path.isdir('CNN_exp/saved_models') :\n",
    "    os.mkdir('CNN_exp/saved_models')\n",
    "cnn.load_model(\"CNN_exp/saved_models/CNN_generator_weights_epoch_200000.hdf5\")\n",
    "test_list = cnn.load_all_images('test data', 'jpg')\n",
    "print(test_list)\n",
    "test_img = cnn.load_images_equivalance_to_names(test_list)\n",
    "masked_imgs = cnn.normalize_imgs(test_img)\n",
    "gen_imgs = cnn.generator.predict(masked_imgs)\n",
    "gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "c = gen_imgs.shape[0]\n",
    "for i in range(c):\n",
    "    cv2.imwrite('{epoch}_generated_1x{image_at_idx}.jpg'.format(epoch = str(i).zfill(5), \n",
    "                                                                                         image_at_idx = i),\n",
    "                cv2.cvtColor(np.array(gen_imgs[i]*255, dtype = 'uint8'),cv2.COLOR_RGB2BGR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
